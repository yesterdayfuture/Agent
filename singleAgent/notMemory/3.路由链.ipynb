{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建路由链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"api_key\")\n",
    "base_url = os.getenv(\"base_url\")\n",
    "\n",
    "online_llm = ChatOpenAI(\n",
    "    api_key=api_key,\n",
    "    model=\"qwen-plus\",\n",
    "    base_url=base_url,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 路由链相关环境\n",
    "from langchain.chains import LLMChain, ConversationChain\n",
    "from langchain.chains.router import MultiRouteChain, LLMRouterChain, MultiPromptChain\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 底层 目标链的prompt\n",
    "math_prompt = \"\"\"\n",
    "你是一位数学家，请根据以下问题，生成对应的数学公式.内容：{input}\n",
    "\"\"\"\n",
    "\n",
    "weather_prompt = \"\"\"你是一位天气预报员，请根据以下问题，生成对应的天气信息.内容：{input}\"\"\"\n",
    "news_prompt = \"\"\"你是一位新闻工作者，请根据以下问题，生成对应的新闻内容.内容：{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#提示词模版 相关信息\n",
    "prompt_info = [\n",
    "    {\n",
    "        \"name\": \"math\",\n",
    "        \"description\": \"数学问题\",\n",
    "        \"prompt\": math_prompt\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"weather\",\n",
    "        \"description\": \"天气问题\",\n",
    "        \"prompt\": weather_prompt\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"news\",\n",
    "        \"description\": \"新闻问题\",\n",
    "        \"prompt\": news_prompt\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'math': LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='\\n你是一位数学家，请根据以下问题，生成对应的数学公式.内容：{input}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x10cf81550>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10cac21d0>, root_client=<openai.OpenAI object at 0x10d3e1010>, root_async_client=<openai.AsyncOpenAI object at 0x10d604390>, model_name='qwen-plus', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1'), output_parser=StrOutputParser(), llm_kwargs={}), 'weather': LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='你是一位天气预报员，请根据以下问题，生成对应的天气信息.内容：{input}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x10cf81550>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10cac21d0>, root_client=<openai.OpenAI object at 0x10d3e1010>, root_async_client=<openai.AsyncOpenAI object at 0x10d604390>, model_name='qwen-plus', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1'), output_parser=StrOutputParser(), llm_kwargs={}), 'news': LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='你是一位新闻工作者，请根据以下问题，生成对应的新闻内容.内容：{input}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x10cf81550>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10cac21d0>, root_client=<openai.OpenAI object at 0x10d3e1010>, root_async_client=<openai.AsyncOpenAI object at 0x10d604390>, model_name='qwen-plus', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1'), output_parser=StrOutputParser(), llm_kwargs={})}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xh/fl5j9g1n5t79htj8yk1cswzh0000gn/T/ipykernel_18361/2015125349.py:4: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=online_llm, prompt=PromptTemplate.from_template(template=info[\"prompt\"]))\n"
     ]
    }
   ],
   "source": [
    "#定义 目标链\n",
    "chains = {}\n",
    "for info in prompt_info:\n",
    "    chain = LLMChain(llm=online_llm, prompt=PromptTemplate.from_template(template=info[\"prompt\"]))\n",
    "    chains[info[\"name\"]] = chain\n",
    "\n",
    "print(chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xh/fl5j9g1n5t79htj8yk1cswzh0000gn/T/ipykernel_18361/3167257219.py:2: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  default_chain = ConversationChain(llm=online_llm,output_key=\"text\")\n",
      "/Users/zhangtian/miniforge3/envs/langchain/lib/python3.11/site-packages/pydantic/main.py:214: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    }
   ],
   "source": [
    "#定义默认链\n",
    "default_chain = ConversationChain(llm=online_llm,output_key=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#路由配置\n",
    "prompt_info = [\n",
    "    \"math:你是一位数学家，请根据以下问题，生成对应的数学公式\",\n",
    "    \"weather:你是一位天气预报员，请根据以下问题，生成对应的天气信息\",\n",
    "    \"news:你是一位新闻工作者，请根据以下问题，生成对应的新闻内容\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "路由模版是： Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "math:你是一位数学家，请根据以下问题，生成对应的数学公式\n",
      "weather:你是一位天气预报员，请根据以下问题，生成对应的天气信息\n",
      "news:你是一位新闻工作者，请根据以下问题，生成对应的新闻内容\n",
      "\n",
      "<< INPUT >>\n",
      "{input}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n",
      "路由模版router_prompt 是： input_variables=['input'] input_types={} output_parser=RouterOutputParser() partial_variables={} template='Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\\n\\n<< FORMATTING >>\\nReturn a markdown code snippet with a JSON object formatted to look like:\\n```json\\n{{\\n    \"destination\": string \\\\ name of the prompt to use or \"DEFAULT\"\\n    \"next_inputs\": string \\\\ a potentially modified version of the original input\\n}}\\n```\\n\\nREMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\\nREMEMBER: \"next_inputs\" can just be the original input if you don\\'t think any modifications are needed.\\n\\n<< CANDIDATE PROMPTS >>\\nmath:你是一位数学家，请根据以下问题，生成对应的数学公式\\nweather:你是一位天气预报员，请根据以下问题，生成对应的天气信息\\nnews:你是一位新闻工作者，请根据以下问题，生成对应的新闻内容\\n\\n<< INPUT >>\\n{input}\\n\\n<< OUTPUT (must include ```json at the start of the response) >>\\n<< OUTPUT (must end with ```) >>\\n'\n"
     ]
    }
   ],
   "source": [
    "#构建路由模版\n",
    "\n",
    "\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations = \"\\n\".join(prompt_info))\n",
    "print(\"路由模版是：\",router_template)\n",
    "\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    # template=\"\\n\".join(prompt_info),\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser()\n",
    "    )\n",
    "print(\"路由模版router_prompt 是：\",router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建路由链\n",
    "router_chain = LLMRouterChain.from_llm(llm=online_llm, prompt=router_prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xh/fl5j9g1n5t79htj8yk1cswzh0000gn/T/ipykernel_18361/2494765385.py:2: LangChainDeprecationWarning: Please see migration guide here for recommended implementation: https://python.langchain.com/docs/versions/migrating_chains/multi_prompt_chain/\n",
      "  expert_chain = MultiPromptChain(\n"
     ]
    }
   ],
   "source": [
    "#构建最终路由链，将路由链和默认链组合\n",
    "expert_chain = MultiPromptChain(\n",
    "    router_chain=router_chain, #路由链\n",
    "    destination_chains=chains, #路由链对应的链\n",
    "    default_chain=default_chain, #默认链\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题： 今天北京天气怎么样？\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMRouterChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "weather: {'input': '今天北京天气怎么样？'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "回答： {'input': '今天北京天气怎么样？', 'text': '大家好，这里是天气预报时间！接下来为您带来今天北京的天气情况：\\n\\n今天北京以晴间多云天气为主，白天阳光明媚，紫外线较强，建议市民外出时做好防晒措施。白天气温较高，预计最高气温将达到28℃左右，早晚较为舒适，最低气温约为16℃，昼夜温差较大，请适时增减衣物，以免着凉。\\n\\n此外，今天北京的空气质量良好，AQI指数在70左右，适合户外活动。不过，风力稍大，偏北风3-4级，阵风可达5级，请注意防风。总体来说，今天的天气适宜出行和各种户外活动，祝您拥有愉快的一天！\\n\\n以上就是今天北京的天气预报，感谢您的收听！'}\n",
      "问题： 请给我一个数学题，简单一点的\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMRouterChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "math: {'input': '请生成一个简单的数学题'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "回答： {'input': '请生成一个简单的数学题', 'text': '当然！以下是一个简单的数学问题及其对应的数学公式：\\n\\n**问题：**  \\n小明有 5 个苹果，他从市场上又买了 3 个苹果。请问小明一共有多少个苹果？\\n\\n**数学公式：**  \\n$$\\n\\\\text{总数} = 5 + 3\\n$$\\n\\n如果需要更复杂的题目，请告诉我！'}\n",
      "问题： 最近有什么新闻吗？\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMRouterChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "news: {'input': '最近有什么新闻吗？'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "回答： {'input': '最近有什么新闻吗？', 'text': '标题：全球科技与环境动态：近期新闻概览\\n\\n近日，国际社会在科技发展与环境保护领域迎来了一系列重要新闻，以下为具体报道：\\n\\n一、科技创新方面\\n\\n1. 人工智能新突破\\n近日，一家知名科技公司宣布其最新研发的人工智能模型已具备更强的理解和生成能力。该模型不仅能够进行多语言文本处理，还能够在艺术创作、科学推理等方面展现出色表现。这一技术进步被认为将极大推动各行业的智能化转型。\\n\\n2. 新能源汽车技术进展\\n某汽车制造商成功开发出一种新型电池技术，使得电动车的续航里程得到显著提升，同时充电时间大幅缩短。这项创新有望加速新能源汽车在全球范围内的普及，减少对传统燃油车的依赖。\\n\\n二、环境保护方面\\n\\n1. 气候变化应对措施\\n联合国气候变化大会日前召开特别会议，讨论如何更有效地减缓全球变暖趋势。各国代表一致同意加强合作，通过提高能效、推广可再生能源等方式减少温室气体排放，并承诺加大对发展中国家的支持力度。\\n\\n2. 生物多样性保护行动\\n为遏制生物多样性丧失速度加快的问题，多个环保组织联合发起了一项旨在恢复自然生态系统的计划。该计划包括重新造林、湿地修复以及建立更多野生动植物保护区等内容，力求为地球上的生命创造更加和谐共生的环境。\\n\\n以上便是最近值得关注的一些新闻要点，从中我们可以看到人类在追求科技进步的同时，也在努力寻找与自然和谐共处之道。未来的发展方向值得我们共同期待！'}\n",
      "问题： 你叫什么名字？\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMRouterChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "None: {'input': '你叫什么名字？'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "回答： {'input': '你叫什么名字？', 'history': '', 'text': '我叫通义千问，英文名是Qwen。我是阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。很高兴为您服务！如果您有任何问题，欢迎随时向我提问。'}\n",
      "问题： 请你写一首诗，歌颂祖国\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMRouterChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "None: {'input': '请你写一首诗，歌颂祖国'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "回答： {'input': '请你写一首诗，歌颂祖国', 'history': 'Human: 你叫什么名字？\\nAI: 我叫通义千问，英文名是Qwen。我是阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。很高兴为您服务！如果您有任何问题，欢迎随时向我提问。', 'text': '以下是赞美祖国大好河山和伟大成就的诗：\\n\\n**《颂祖国》**\\n\\n华夏文明耀古今，山河壮丽谱雄音。\\n长城万里风云绕，碧海千帆岁月吟。\\n科技腾飞惊世目，民生改善暖人心。\\n中华复兴宏图展，伟业千秋颂国林。\\n\\n解析：首联点明华夏文明贯穿古今，祖国的山河非常壮丽，从而奠定歌颂的基调。颔联通过具体意象“长城”和“碧海”，展现出祖国历史的厚重与自然风光的迷人。颈联则转向现代社会，强调科技发展令人瞩目，民生不断改善使人民感受到温暖。尾联展望未来，表明中华民族伟大复兴的美好前景，以及这伟大的事业将永远被传颂。'}\n"
     ]
    }
   ],
   "source": [
    "#调用最终链\n",
    "\n",
    "question = [\n",
    "    \"今天北京天气怎么样？\",\n",
    "    \"请给我一个数学题，简单一点的\",\n",
    "    \"最近有什么新闻吗？\",\n",
    "    \"你叫什么名字？\",\n",
    "    \"请你写一首诗，歌颂祖国\"\n",
    "]\n",
    "\n",
    "for q in question:\n",
    "    print(\"问题：\",q)\n",
    "    print(\"回答：\",expert_chain.invoke({\"input\":q}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
